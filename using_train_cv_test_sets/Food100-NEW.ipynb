{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "matplotlib.use('Agg') \n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 960M (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32,exception_verbosity=high\"\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, SpatialDropout2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "train_data_dir = '../UECFOOD100/data/train'\n",
    "validation_data_dir = '../UECFOOD100/data/validation'\n",
    "nb_train_samples = 10183\n",
    "nb_validation_samples = 4428\n",
    "nb_epoch = 50\n",
    "batch_size = 32\n",
    "\n",
    "# path to the model weights file.\n",
    "weights_path = 'D:/DSR/neural-networks-and-deep-learning/CatsandDogs/models/vgg16_weights.h5'\n",
    "top_model_weights_path = './bottleneck_features_11_12_2016.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # this is the augmentation configuration we will use for training\n",
    "# train_augmentations = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "# # this is the augmentation configuration we will use for testing:\n",
    "# # only rescaling\n",
    "# test_augmentations = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train_generator = train_augmentations.flow_from_directory(\n",
    "#         train_data_dir,\n",
    "#         target_size=(img_width, img_height),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "# validation_generator = test_augmentations.flow_from_directory(\n",
    "#         validation_data_dir,\n",
    "#         target_size=(img_width, img_height),\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Found 10183 images belonging to 100 classes.\n",
      "Found 4428 images belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "#Extract bottleneck features usng VGG16:\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# build the VGG16 network\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# load the weights of the VGG16 networks\n",
    "# (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "# note: when there is a complete match between your model definition\n",
    "# and your weight savefile, you can simply call model.load_weights(filename)\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')\n",
    "\n",
    "train_bottleneck_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "train_labels = train_bottleneck_generator.classes\n",
    "\n",
    "bottleneck_features_train = model.predict_generator(train_bottleneck_generator, nb_train_samples)\n",
    "\n",
    "np.save(open('bottleneck_features_train_12_2016.npy', 'ba'), bottleneck_features_train)\n",
    "\n",
    "validation_bottleneck_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "validation_labels = validation_bottleneck_generator.classes\n",
    "\n",
    "bottleneck_features_validation = model.predict_generator(validation_bottleneck_generator, nb_validation_samples)\n",
    "np.save(open('bottleneck_features_validation_12_2016.npy', 'ba'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 99, 99, 99])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_bottleneck_generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10183 samples, validate on 4428 samples\n",
      "Epoch 1/100\n",
      "10183/10183 [==============================] - 2s - loss: 4.5298 - acc: 0.0407 - val_loss: 4.4191 - val_acc: 0.0598\n",
      "Epoch 2/100\n",
      "10183/10183 [==============================] - 2s - loss: 4.3906 - acc: 0.0629 - val_loss: 4.2527 - val_acc: 0.0879\n",
      "Epoch 3/100\n",
      "10183/10183 [==============================] - 2s - loss: 4.2393 - acc: 0.0774 - val_loss: 4.0609 - val_acc: 0.1129\n",
      "Epoch 4/100\n",
      "10183/10183 [==============================] - 2s - loss: 4.0738 - acc: 0.0902 - val_loss: 3.8605 - val_acc: 0.1163\n",
      "Epoch 5/100\n",
      "10183/10183 [==============================] - 2s - loss: 3.9118 - acc: 0.1083 - val_loss: 3.6328 - val_acc: 0.1484\n",
      "Epoch 6/100\n",
      "10183/10183 [==============================] - 2s - loss: 3.7436 - acc: 0.1225 - val_loss: 3.4321 - val_acc: 0.1518\n",
      "Epoch 7/100\n",
      "10183/10183 [==============================] - 2s - loss: 3.5897 - acc: 0.1528 - val_loss: 3.2712 - val_acc: 0.2103\n",
      "Epoch 8/100\n",
      "10183/10183 [==============================] - 2s - loss: 3.4144 - acc: 0.1789 - val_loss: 3.0482 - val_acc: 0.2624\n",
      "Epoch 9/100\n",
      "10183/10183 [==============================] - 2s - loss: 3.2672 - acc: 0.1978 - val_loss: 2.8808 - val_acc: 0.3234\n",
      "Epoch 10/100\n",
      "10183/10183 [==============================] - 2s - loss: 3.1112 - acc: 0.2430 - val_loss: 2.7828 - val_acc: 0.2866\n",
      "Epoch 11/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.9786 - acc: 0.2609 - val_loss: 2.6822 - val_acc: 0.3238\n",
      "Epoch 12/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.8586 - acc: 0.2913 - val_loss: 2.5835 - val_acc: 0.3681\n",
      "Epoch 13/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.7363 - acc: 0.3127 - val_loss: 2.5236 - val_acc: 0.3668\n",
      "Epoch 14/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.6444 - acc: 0.3298 - val_loss: 2.4718 - val_acc: 0.3808\n",
      "Epoch 15/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.5701 - acc: 0.3489 - val_loss: 2.3822 - val_acc: 0.4024\n",
      "Epoch 16/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.4712 - acc: 0.3688 - val_loss: 2.4762 - val_acc: 0.3715\n",
      "Epoch 17/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.4135 - acc: 0.3832 - val_loss: 2.2502 - val_acc: 0.4397\n",
      "Epoch 18/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.3211 - acc: 0.3968 - val_loss: 2.3520 - val_acc: 0.3850\n",
      "Epoch 19/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.2696 - acc: 0.4181 - val_loss: 2.1990 - val_acc: 0.4289\n",
      "Epoch 20/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.2189 - acc: 0.4211 - val_loss: 2.2343 - val_acc: 0.4079\n",
      "Epoch 21/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.1431 - acc: 0.4447 - val_loss: 2.1853 - val_acc: 0.4485\n",
      "Epoch 22/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.1101 - acc: 0.4456 - val_loss: 2.1264 - val_acc: 0.4533\n",
      "Epoch 23/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.0441 - acc: 0.4590 - val_loss: 2.1394 - val_acc: 0.4562\n",
      "Epoch 24/100\n",
      "10183/10183 [==============================] - 2s - loss: 2.0050 - acc: 0.4727 - val_loss: 2.1242 - val_acc: 0.4359\n",
      "Epoch 25/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.9751 - acc: 0.4788 - val_loss: 2.0168 - val_acc: 0.4871\n",
      "Epoch 26/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.9318 - acc: 0.4883 - val_loss: 2.0071 - val_acc: 0.4740\n",
      "Epoch 27/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.8973 - acc: 0.4908 - val_loss: 2.0785 - val_acc: 0.4553\n",
      "Epoch 28/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.8481 - acc: 0.5024 - val_loss: 1.9708 - val_acc: 0.4815\n",
      "Epoch 29/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.8092 - acc: 0.5176 - val_loss: 1.9108 - val_acc: 0.5009\n",
      "Epoch 30/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.7801 - acc: 0.5278 - val_loss: 1.9638 - val_acc: 0.4797\n",
      "Epoch 31/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.7472 - acc: 0.5345 - val_loss: 1.9798 - val_acc: 0.4779\n",
      "Epoch 32/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.7091 - acc: 0.5417 - val_loss: 2.0171 - val_acc: 0.4607\n",
      "Epoch 33/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.6844 - acc: 0.5459 - val_loss: 1.8719 - val_acc: 0.5029\n",
      "Epoch 34/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.6529 - acc: 0.5518 - val_loss: 1.9918 - val_acc: 0.4835\n",
      "Epoch 35/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.6211 - acc: 0.5644 - val_loss: 1.9230 - val_acc: 0.4880\n",
      "Epoch 36/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.5911 - acc: 0.5739 - val_loss: 1.8527 - val_acc: 0.5124\n",
      "Epoch 37/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.5656 - acc: 0.5717 - val_loss: 1.9550 - val_acc: 0.4894\n",
      "Epoch 38/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.5383 - acc: 0.5811 - val_loss: 1.9229 - val_acc: 0.4944\n",
      "Epoch 39/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.5060 - acc: 0.5890 - val_loss: 1.9935 - val_acc: 0.4772\n",
      "Epoch 40/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.4717 - acc: 0.5959 - val_loss: 1.8690 - val_acc: 0.4995\n",
      "Epoch 41/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.4376 - acc: 0.6042 - val_loss: 1.9227 - val_acc: 0.4939\n",
      "Epoch 42/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.4390 - acc: 0.6069 - val_loss: 1.8436 - val_acc: 0.5077\n",
      "Epoch 43/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.4210 - acc: 0.6098 - val_loss: 1.8957 - val_acc: 0.4923\n",
      "Epoch 44/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.3802 - acc: 0.6184 - val_loss: 1.7811 - val_acc: 0.5233\n",
      "Epoch 45/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.3631 - acc: 0.6262 - val_loss: 1.8130 - val_acc: 0.5187\n",
      "Epoch 46/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.3456 - acc: 0.6280 - val_loss: 1.8401 - val_acc: 0.5027\n",
      "Epoch 47/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.3186 - acc: 0.6404 - val_loss: 1.7304 - val_acc: 0.5370\n",
      "Epoch 48/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.2971 - acc: 0.6393 - val_loss: 1.7324 - val_acc: 0.5382\n",
      "Epoch 49/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.2792 - acc: 0.6457 - val_loss: 1.7321 - val_acc: 0.5364\n",
      "Epoch 50/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.2544 - acc: 0.6530 - val_loss: 1.8317 - val_acc: 0.5113\n",
      "Epoch 51/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.2309 - acc: 0.6587 - val_loss: 1.8883 - val_acc: 0.4989\n",
      "Epoch 52/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.1956 - acc: 0.6648 - val_loss: 1.8002 - val_acc: 0.5196\n",
      "Epoch 53/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.1865 - acc: 0.6669 - val_loss: 1.7776 - val_acc: 0.5242\n",
      "Epoch 54/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.1888 - acc: 0.6669 - val_loss: 1.7650 - val_acc: 0.5282\n",
      "Epoch 55/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.1559 - acc: 0.6800 - val_loss: 1.7740 - val_acc: 0.5273\n",
      "Epoch 56/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.1366 - acc: 0.6795 - val_loss: 1.7321 - val_acc: 0.5409\n",
      "Epoch 57/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.1238 - acc: 0.6846 - val_loss: 1.6811 - val_acc: 0.5477\n",
      "Epoch 58/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.0902 - acc: 0.6945 - val_loss: 1.7916 - val_acc: 0.5156\n",
      "Epoch 59/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.0716 - acc: 0.6940 - val_loss: 1.7369 - val_acc: 0.5348\n",
      "Epoch 60/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.0510 - acc: 0.7049 - val_loss: 1.9793 - val_acc: 0.4828\n",
      "Epoch 61/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.0593 - acc: 0.7034 - val_loss: 1.7014 - val_acc: 0.5486\n",
      "Epoch 62/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.0231 - acc: 0.7179 - val_loss: 1.7769 - val_acc: 0.5260\n",
      "Epoch 63/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.0171 - acc: 0.7167 - val_loss: 1.7582 - val_acc: 0.5303\n",
      "Epoch 64/100\n",
      "10183/10183 [==============================] - 2s - loss: 1.0010 - acc: 0.7231 - val_loss: 1.7011 - val_acc: 0.5481\n",
      "Epoch 65/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.9744 - acc: 0.7251 - val_loss: 1.7826 - val_acc: 0.5251\n",
      "Epoch 66/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.9769 - acc: 0.7266 - val_loss: 1.7352 - val_acc: 0.5395\n",
      "Epoch 67/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.9432 - acc: 0.7330 - val_loss: 1.7100 - val_acc: 0.5434\n",
      "Epoch 68/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.9489 - acc: 0.7344 - val_loss: 1.7645 - val_acc: 0.5300\n",
      "Epoch 69/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.9124 - acc: 0.7461 - val_loss: 1.7376 - val_acc: 0.5440\n",
      "Epoch 70/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.8933 - acc: 0.7475 - val_loss: 1.6490 - val_acc: 0.5603\n",
      "Epoch 71/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.8831 - acc: 0.7483 - val_loss: 1.8655 - val_acc: 0.5140\n",
      "Epoch 72/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.8746 - acc: 0.7562 - val_loss: 1.7353 - val_acc: 0.5404\n",
      "Epoch 73/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.8489 - acc: 0.7587 - val_loss: 1.6992 - val_acc: 0.5506\n",
      "Epoch 74/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.8492 - acc: 0.7572 - val_loss: 1.7577 - val_acc: 0.5336\n",
      "Epoch 75/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.8402 - acc: 0.7675 - val_loss: 1.7198 - val_acc: 0.5397\n",
      "Epoch 76/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.8256 - acc: 0.7717 - val_loss: 1.7595 - val_acc: 0.5402\n",
      "Epoch 77/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.8063 - acc: 0.7701 - val_loss: 1.9221 - val_acc: 0.5081\n",
      "Epoch 78/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.7963 - acc: 0.7795 - val_loss: 1.7968 - val_acc: 0.5291\n",
      "Epoch 79/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.7769 - acc: 0.7807 - val_loss: 1.7291 - val_acc: 0.5388\n",
      "Epoch 80/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.7843 - acc: 0.7781 - val_loss: 1.6700 - val_acc: 0.5592\n",
      "Epoch 81/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.7493 - acc: 0.7864 - val_loss: 1.6873 - val_acc: 0.5558\n",
      "Epoch 82/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.7471 - acc: 0.7915 - val_loss: 1.7522 - val_acc: 0.5361\n",
      "Epoch 83/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.7343 - acc: 0.7945 - val_loss: 1.8347 - val_acc: 0.5264\n",
      "Epoch 84/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.7232 - acc: 0.7973 - val_loss: 1.8334 - val_acc: 0.5280\n",
      "Epoch 85/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.7079 - acc: 0.8014 - val_loss: 1.7500 - val_acc: 0.5431\n",
      "Epoch 86/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.7065 - acc: 0.8017 - val_loss: 1.7074 - val_acc: 0.5569\n",
      "Epoch 87/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.6992 - acc: 0.8051 - val_loss: 1.6703 - val_acc: 0.5583\n",
      "Epoch 88/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.6819 - acc: 0.8073 - val_loss: 1.8366 - val_acc: 0.5251\n",
      "Epoch 89/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.6839 - acc: 0.8111 - val_loss: 1.9245 - val_acc: 0.5131\n",
      "Epoch 90/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.6678 - acc: 0.8106 - val_loss: 1.7008 - val_acc: 0.5483\n",
      "Epoch 91/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.6456 - acc: 0.8172 - val_loss: 1.7037 - val_acc: 0.5571\n",
      "Epoch 92/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.6363 - acc: 0.8198 - val_loss: 1.6830 - val_acc: 0.5580\n",
      "Epoch 93/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.6282 - acc: 0.8230 - val_loss: 1.7262 - val_acc: 0.5551\n",
      "Epoch 94/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.6218 - acc: 0.8247 - val_loss: 1.6527 - val_acc: 0.5644\n",
      "Epoch 95/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.5985 - acc: 0.8327 - val_loss: 1.8156 - val_acc: 0.5276\n",
      "Epoch 96/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.6169 - acc: 0.8269 - val_loss: 1.7066 - val_acc: 0.5531\n",
      "Epoch 97/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.5898 - acc: 0.8332 - val_loss: 2.0049 - val_acc: 0.4957\n",
      "Epoch 98/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.6115 - acc: 0.8328 - val_loss: 1.6533 - val_acc: 0.5619\n",
      "Epoch 99/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.5747 - acc: 0.8359 - val_loss: 1.8135 - val_acc: 0.5379\n",
      "Epoch 100/100\n",
      "10183/10183 [==============================] - 2s - loss: 0.5669 - acc: 0.8424 - val_loss: 1.8287 - val_acc: 0.5280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x293a0edc828>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_encoded = np.zeros((len(train_labels), 100), dtype=int)\n",
    "for index, element in enumerate(train_labels):\n",
    "    train_labels_encoded[index,element] = 1\n",
    "validation_labels_encoded = np.zeros((len(validation_labels), 100), dtype=int)\n",
    "for index, element in enumerate(validation_labels):\n",
    "    validation_labels_encoded[index,element] = 1\n",
    "\n",
    "sgd = SGD(lr=0.01, clipnorm=1.)\n",
    "\n",
    "# bottleneck_features_train = np.load(open('bottleneck_features_train_12_2016.npy','rb'))\n",
    "# bottleneck_features_validation = np.load(open('bottleneck_features_validation_12_2016.npy', 'rb'))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=bottleneck_features_train.shape[1:]))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 100\n",
    "\n",
    "model.fit(bottleneck_features_train, train_labels_encoded,\n",
    "          nb_epoch=nb_epoch, \n",
    "          batch_size=32,\n",
    "          validation_data=(bottleneck_features_validation, validation_labels_encoded))\n",
    "\n",
    "nb_epoch = 50\n",
    "\n",
    "##### model.save_weights(top_model_weights_path)\n",
    "# model.save_weights('./bottleneck_fc_model_11_12_16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(512, 4, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "# load the weights of the VGG16 networks\n",
    "# (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "# note: when there is a complete match between your model definition\n",
    "# and your weight savefile, you can simply call model.load_weights(filename)\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')\n",
    "model.output_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10183 images belonging to 100 classes.\n",
      "Found 4428 images belonging to 100 classes.\n",
      "Epoch 1/50\n",
      "10183/10183 [==============================] - 524s - loss: 2.8294 - acc: 0.3113 - val_loss: 1.8002 - val_acc: 0.5300\n",
      "Epoch 2/50\n",
      "10183/10183 [==============================] - 525s - loss: 2.5478 - acc: 0.3606 - val_loss: 1.6803 - val_acc: 0.5556\n",
      "Epoch 3/50\n",
      "10183/10183 [==============================] - 530s - loss: 2.4265 - acc: 0.3769 - val_loss: 1.6622 - val_acc: 0.5619\n",
      "Epoch 4/50\n",
      "10183/10183 [==============================] - 524s - loss: 2.3704 - acc: 0.3899 - val_loss: 1.6379 - val_acc: 0.5693\n",
      "Epoch 5/50\n",
      "10183/10183 [==============================] - 522s - loss: 2.2832 - acc: 0.4153 - val_loss: 1.6525 - val_acc: 0.5596\n",
      "Epoch 6/50\n",
      "10183/10183 [==============================] - 522s - loss: 2.2652 - acc: 0.4149 - val_loss: 1.6262 - val_acc: 0.5734\n",
      "Epoch 7/50\n",
      "10183/10183 [==============================] - 523s - loss: 2.2424 - acc: 0.4235 - val_loss: 1.5962 - val_acc: 0.5725\n",
      "Epoch 8/50\n",
      "10183/10183 [==============================] - 522s - loss: 2.1570 - acc: 0.4424 - val_loss: 1.5802 - val_acc: 0.5775\n",
      "Epoch 9/50\n",
      "10183/10183 [==============================] - 523s - loss: 2.1134 - acc: 0.4465 - val_loss: 1.5447 - val_acc: 0.5847\n",
      "Epoch 10/50\n",
      "10183/10183 [==============================] - 523s - loss: 2.0979 - acc: 0.4535 - val_loss: 1.5630 - val_acc: 0.5827\n",
      "Epoch 11/50\n",
      "10183/10183 [==============================] - 524s - loss: 2.0951 - acc: 0.4527 - val_loss: 1.4944 - val_acc: 0.5978\n",
      "Epoch 12/50\n",
      "10183/10183 [==============================] - 523s - loss: 2.0347 - acc: 0.4669 - val_loss: 1.5504 - val_acc: 0.5851\n",
      "Epoch 13/50\n",
      "10183/10183 [==============================] - 523s - loss: 2.0153 - acc: 0.4697 - val_loss: 1.4810 - val_acc: 0.6073\n",
      "Epoch 14/50\n",
      "10183/10183 [==============================] - 525s - loss: 1.9830 - acc: 0.4699 - val_loss: 1.5582 - val_acc: 0.5960\n",
      "Epoch 15/50\n",
      "10183/10183 [==============================] - 525s - loss: 1.9484 - acc: 0.4865 - val_loss: 1.4907 - val_acc: 0.6000\n",
      "Epoch 16/50\n",
      "10183/10183 [==============================] - 523s - loss: 1.9439 - acc: 0.4885 - val_loss: 1.4395 - val_acc: 0.6122\n",
      "Epoch 17/50\n",
      "10183/10183 [==============================] - 524s - loss: 1.9151 - acc: 0.4894 - val_loss: 1.4872 - val_acc: 0.6093\n",
      "Epoch 18/50\n",
      "10183/10183 [==============================] - 524s - loss: 1.8918 - acc: 0.4885 - val_loss: 1.4794 - val_acc: 0.6091\n",
      "Epoch 19/50\n",
      "10183/10183 [==============================] - 524s - loss: 1.8711 - acc: 0.5045 - val_loss: 1.4483 - val_acc: 0.6084\n",
      "Epoch 20/50\n",
      "10183/10183 [==============================] - 526s - loss: 1.8488 - acc: 0.5071 - val_loss: 1.3902 - val_acc: 0.6206\n",
      "Epoch 21/50\n",
      "10183/10183 [==============================] - 526s - loss: 1.8463 - acc: 0.5043 - val_loss: 1.4549 - val_acc: 0.6192\n",
      "Epoch 22/50\n",
      "10183/10183 [==============================] - 525s - loss: 1.8199 - acc: 0.5113 - val_loss: 1.5144 - val_acc: 0.6129\n",
      "Epoch 23/50\n",
      "10183/10183 [==============================] - 530s - loss: 1.8152 - acc: 0.5145 - val_loss: 1.3834 - val_acc: 0.6249\n",
      "Epoch 24/50\n",
      "10183/10183 [==============================] - 533s - loss: 1.7845 - acc: 0.5169 - val_loss: 1.4110 - val_acc: 0.6278\n",
      "Epoch 25/50\n",
      "10183/10183 [==============================] - 532s - loss: 1.7708 - acc: 0.5272 - val_loss: 1.4760 - val_acc: 0.6050\n",
      "Epoch 26/50\n",
      "10183/10183 [==============================] - 533s - loss: 1.7534 - acc: 0.5274 - val_loss: 1.4621 - val_acc: 0.6070\n",
      "Epoch 27/50\n",
      "10183/10183 [==============================] - 535s - loss: 1.7498 - acc: 0.5317 - val_loss: 1.4004 - val_acc: 0.6238\n",
      "Epoch 28/50\n",
      "10183/10183 [==============================] - 532s - loss: 1.7428 - acc: 0.5265 - val_loss: 1.4668 - val_acc: 0.6079\n",
      "Epoch 29/50\n",
      "10183/10183 [==============================] - 527s - loss: 1.7159 - acc: 0.5333 - val_loss: 1.3813 - val_acc: 0.6303\n",
      "Epoch 30/50\n",
      "10183/10183 [==============================] - 530s - loss: 1.6965 - acc: 0.5407 - val_loss: 1.3782 - val_acc: 0.6244\n",
      "Epoch 31/50\n",
      "10183/10183 [==============================] - 527s - loss: 1.6908 - acc: 0.5369 - val_loss: 1.4056 - val_acc: 0.6231\n",
      "Epoch 32/50\n",
      "10183/10183 [==============================] - 526s - loss: 1.6833 - acc: 0.5446 - val_loss: 1.4052 - val_acc: 0.6247\n",
      "Epoch 33/50\n",
      "10183/10183 [==============================] - 527s - loss: 1.6385 - acc: 0.5548 - val_loss: 1.3706 - val_acc: 0.6294\n",
      "Epoch 34/50\n",
      "10183/10183 [==============================] - 528s - loss: 1.6413 - acc: 0.5546 - val_loss: 1.3732 - val_acc: 0.6339\n",
      "Epoch 35/50\n",
      "10183/10183 [==============================] - 524s - loss: 1.6326 - acc: 0.5585 - val_loss: 1.3693 - val_acc: 0.6330\n",
      "Epoch 36/50\n",
      "10183/10183 [==============================] - 525s - loss: 1.6199 - acc: 0.5572 - val_loss: 1.3217 - val_acc: 0.6443\n",
      "Epoch 37/50\n",
      "10183/10183 [==============================] - 527s - loss: 1.5761 - acc: 0.5631 - val_loss: 1.4286 - val_acc: 0.6172\n",
      "Epoch 38/50\n",
      "10183/10183 [==============================] - 528s - loss: 1.5998 - acc: 0.5640 - val_loss: 1.3573 - val_acc: 0.6344\n",
      "Epoch 39/50\n",
      "10183/10183 [==============================] - 533s - loss: 1.6012 - acc: 0.5656 - val_loss: 1.3976 - val_acc: 0.6222\n",
      "Epoch 40/50\n",
      "10183/10183 [==============================] - 525s - loss: 1.5749 - acc: 0.5720 - val_loss: 1.3164 - val_acc: 0.6479\n",
      "Epoch 41/50\n",
      "10183/10183 [==============================] - 532s - loss: 1.5823 - acc: 0.5667 - val_loss: 1.3348 - val_acc: 0.6380\n",
      "Epoch 42/50\n",
      "10183/10183 [==============================] - 527s - loss: 1.5586 - acc: 0.5761 - val_loss: 1.3653 - val_acc: 0.6323\n",
      "Epoch 43/50\n",
      "10183/10183 [==============================] - 527s - loss: 1.5245 - acc: 0.5816 - val_loss: 1.3639 - val_acc: 0.6332\n",
      "Epoch 44/50\n",
      "10183/10183 [==============================] - 526s - loss: 1.5192 - acc: 0.5802 - val_loss: 1.3325 - val_acc: 0.6387\n",
      "Epoch 45/50\n",
      "10183/10183 [==============================] - 527s - loss: 1.5264 - acc: 0.5819 - val_loss: 1.3843 - val_acc: 0.6308\n",
      "Epoch 46/50\n",
      "10183/10183 [==============================] - 527s - loss: 1.5116 - acc: 0.5900 - val_loss: 1.3640 - val_acc: 0.6341\n",
      "Epoch 47/50\n",
      "10183/10183 [==============================] - 526s - loss: 1.4886 - acc: 0.5882 - val_loss: 1.4123 - val_acc: 0.6195\n",
      "Epoch 48/50\n",
      "10183/10183 [==============================] - 527s - loss: 1.4886 - acc: 0.5908 - val_loss: 1.3206 - val_acc: 0.6375\n",
      "Epoch 49/50\n",
      "10183/10183 [==============================] - 526s - loss: 1.4721 - acc: 0.5929 - val_loss: 1.3611 - val_acc: 0.6348\n",
      "Epoch 50/50\n",
      "10183/10183 [==============================] - 527s - loss: 1.4720 - acc: 0.5945 - val_loss: 1.3677 - val_acc: 0.6364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a5c8972b00>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(100, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights('./bottleneck_fc_model_11_12_16.h5')\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model.add(top_model)\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "# #               optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=60,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save('fine_tuned_model_all_newRun.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}